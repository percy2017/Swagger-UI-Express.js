# Servidor de Herramientas KipuxAI para cualquier cliente compatible con OpenAI

Este proyecto es un **gateway de herramientas modular** construido con **Express.js**. Su prop√≥sito es integrarse con clientes como **Open Web UI**, actuando como un puente centralizado hacia varios servicios backend (SearXNG, Browserless, etc.) y permitiendo un control granular sobre qu√© herramientas est√°n disponibles para el LLM.

A diferencia de un servidor monol√≠tico, esta arquitectura permite registrar cada herramienta de forma individual, d√°ndole al usuario final un interruptor para activar o desactivar cada capacidad.

## ‚ú® Caracter√≠sticas Principales

*   **Control Granular**: Cada herramienta expone su propia especificaci√≥n OpenAPI, permitiendo activarlas y desactivarlas individualmente desde la interfaz del cliente (ej. Open Web UI).
*   **Arquitectura Modular y Escalable**: Cada herramienta vive en su propio m√≥dulo autocontenido (`/tools`), facilitando el mantenimiento y la adici√≥n de nuevas capacidades.
*   **B√∫squeda Multi-Categor√≠a**: La herramienta de b√∫squeda consulta simult√°neamente las categor√≠as `general`, `news`, `videos` e `images` de **SearXNG** y devuelve resultados agregados.
*   **Scraping Avanzado y Generaci√≥n de Artefactos**: La herramienta de scraping usa **Browserless** para extraer metadatos, guardar el contenido completo en formato `.md` y generar capturas de pantalla, devolviendo enlaces a estos recursos para un consumo m√≠nimo de tokens.
*   **Gu√≠a Inteligente para LLMs**: Ambas herramientas incluyen una "sugerencia de presentaci√≥n" en su respuesta para instruir al LLM sobre la mejor manera de presentar la informaci√≥n al usuario.
*   **F√°cil de Configurar**: Utiliza variables de entorno (`.env`) para una configuraci√≥n segura y flexible.

## üèóÔ∏è Arquitectura

El servidor act√∫a como un orquestador. El archivo principal `index.js` no contiene l√≥gica de herramientas; su √∫nica funci√≥n es cargar y registrar los m√≥dulos definidos en la carpeta `/tools`.

Cada subcarpeta dentro de `/tools` es una herramienta independiente y contiene:
1.  `router.js`: La l√≥gica del endpoint (Express.Router).
2.  `spec.js`: La especificaci√≥n OpenAPI para esa herramienta.
3.  `index.js`: Un archivo que exporta el router y la spec para ser consumidos por el servidor principal.

## üìã Requisitos Previos

*   [Node.js](https://nodejs.org/) (v18.x o superior)
*   [npm](https://www.npmjs.com/)
*   Una instancia de **SearXNG** funcionando.
*   Una instancia de **Browserless** funcionando.

## üöÄ Instalaci√≥n y Configuraci√≥n

1.  **Clona el repositorio e instala dependencias:**
    ```bash
    git clone https://github.com/tu-usuario/tu-repositorio.git
    cd tu-repositorio
    npm install
    ```

2.  **Configura tus variables de entorno:**
    Crea un archivo `.env` en la ra√≠z del proyecto y a√±ade las siguientes variables:
    ```dotenv
    # --- Configuraci√≥n General del Servidor ---
    PORT=5005
    # URL p√∫blica base del servidor, sin la barra al final. Esencial para generar los enlaces a los artefactos.
    PUBLIC_SERVER_URL=http://<IP_DE_TU_VPS>:5005

    # --- Configuraci√≥n de Servicios Externos ---
    # URL de tu instancia de SearXNG
    SEARXNG_URL=http://<IP_DE_TU_VPS>:5007

    # URL WebSocket de tu instancia de Browserless
    BROWSERLESS_URL=ws://<IP_DE_TU_VPS>:5006
    # Token de seguridad para Browserless (si lo tienes configurado)
    BROWSERLESS_TOKEN=browserless2025
    ```

## ‚ñ∂Ô∏è Uso

*   **Modo de Desarrollo:**
    ```bash
    npm run dev
    ```
*   **Modo de Producci√≥n:**
    ```bash
    npm start
    ```

## üß™ Pruebas con Postman

Se recomienda usar un cliente de API como **Postman** o **Thunder Client** para las pruebas.

### Probar la Herramienta de B√∫squeda
1.  **M√©todo:** `POST`
2.  **URL:** `http://localhost:5005/api/search/web-search`
3.  **Body (raw, JSON):**
    ```json
    {
      "query": "superconductores a temperatura ambiente",
      "count": 3
    }
    ```

### Probar la Herramienta de Scraping
1.  **M√©todo:** `POST`
2.  **URL:** `http://localhost:5005/api/scrape/scrape-url`
3.  **Body (raw, JSON):**
    ```json
    {
      "url": "https://www.xataka.com"
    }
    ```

## üîó Integraci√≥n con Open Web UI

Para lograr el control granular, debes registrar cada herramienta como un servidor independiente.

1.  En Open Web UI, ve a **Configuraci√≥n > Modelos** y selecciona el modelo a configurar.
2.  Activa **"Herramientas" (Tools)**.
3.  En **"Servidores de Herramientas OpenAPI"**, a√±ade una entrada por cada herramienta:

    *   **Para la B√∫squeda:**
        ```
        http://<IP_DE_TU_VPS>:5005/api/search/openapi.json
        ```
    *   **Para el Scraping (a√±ade una nueva entrada):**
        ```
        http://<IP_DE_TU_VPS>:5005/api/scrape/openapi.json
        ```
4.  Guarda los cambios. Ahora ver√°s ambas herramientas en la lista, cada una con su propio interruptor.

## üó∫Ô∏è Hoja de Ruta (Roadmap)

-   [x] **Implementada Herramienta de B√∫squeda Multi-Categor√≠a** con SearXNG.
-   [x] **Implementada Herramienta de Scraping Avanzado** con Browserless, generando artefactos y enlaces.
-   [ ] **Crear el m√≥dulo de herramienta para extracci√≥n de texto con Apache Tika.**
-   [ ] Centralizar el manejo de errores con un middleware global.
-   [ ] Implementar un sistema de limpieza para los artefactos generados en la carpeta `/static`.